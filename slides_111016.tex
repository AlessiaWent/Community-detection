\documentclass{beamer}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsfonts,amssymb,amsthm,textcomp, wasysym, xcolor, listings}
\usepackage{graphicx}
\usepackage[all]{xy}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\lstset{basicstyle=\ttfamily\scriptsize,
  showstringspaces=false,
  commentstyle=\color{red},
  keywordstyle=\color{blue}
}

\usetheme{Madrid}        % layout complessivo. 
\useinnertheme{default} % layout interno.
\useoutertheme{default} % layout esterno.
\usecolortheme{beaver} % schema di colori.
\usefonttheme{default}  % schema dei font.
% Inutile dire che se volete tutti i default, potete risparmiarvi gli ultimi
% quattro comandi. 

%%% Titolo e autore.
\title{Community detection work}
\institute{MHPC}
\date{\today}

\begin{document}

\begin{frame}
 \titlepage
\end{frame}
\section{Introduzione}
\frame{\sectionpage}
\begin{frame}
 \frametitle{Lavoro svolto}
  \begin{itemize}
  \item Lavoro preliminare (agosto):
  \begin{itemize}
  \item Analisi e discussione della struttura delle tabelle
  \item Discussione su come procedere per l'analisi e quale parte del database utilizzare
  \item Creazione di files-tabelle a partire dai csv originari per leggere più velocemente i dati necessari per la costruzione di link 
  \end{itemize}
  \item Implementazione algoritmi (Python)
  \item Analisi delle performance, ottimizzazione
  \item Analisi dei risultati richiesti
  \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Stato dei lavori}
 Completata l'analisi su un sottocampione di dati (soggetti registrati negli ultimi 6 mesi, circa 1M nodi) delle communities ottenute tramite i soli link di tipo "broker"
  \begin{itemize}
  \item Due algoritmi di clustering, implementati in Python:
  \begin{itemize}
  \item DBSCAN, algoritmo basato sulla \textit{distanza} tra due nodi
  \item Label propagation, algoritmo di clustering su network (community detection) basato sulla \textit{similarit\`{a}} tra due nodi
  \end{itemize}
  \item Due librerie Python per la parallelizzazione della parte computazionalmente pi\`{u} pesante (calcolo delle connessioni):
  \begin{itemize}
  \item Parallel Python
  \item Multiprocessing (memoria condivisa)
  \end{itemize}
  \end{itemize}
\end{frame}


\begin{frame}
\frametitle{DBSCAN}
Basato sul concetto di \textit{densit\`{a} locale}, ovvero il numero di nodi a distanza minore di una distanza fissata $\varepsilon$.\\
Idea: un \textit{core point} è un punto con densit\`{a} locale maggiore di un valore fissato $m$ (che viene dato come parametro, 15 nel nostro caso). Due punti $p$ e $q$ apparterranno allo stesso cluster se esiste nel grafo un cammino
$$
p = p_0 p_1\cdots p_n = q
$$
per cui tutti i punti da $p_1$ a $p_{n-1}$ sono core points.\\

Tutti i punti non raggiungibili da nessun core point sono considerati \textit{noise}, e non apparterranno a nessun cluster/community.
\end{frame}
\begin{frame}
\frametitle{DBSCAN - esempio}
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{DBSCAN.png}

\end{figure}

\end{frame}

\begin{frame}
\frametitle{Label propagation}
Idea: ogni nodo è provvisto di una \textit{label}, che indica l'id della community a cui appartiene. 
Si procede in 4 steps:
\begin{enumerate}
\item Inizialmente, si setta ogni nodo con una label diversa (il nodo $i$ ha label $i$)
\item Si permuta randomicamente la lista dei nodi
\item Secondo l'ordine ottenuto, si sostituisce la label di ogni nodo con quella che appare più frequentemente tra i vari neighbors, tenendo conto di eventuali pesi (in caso di parità, la label verrà scelta randomicamente tra le più frequenti)
\item Si controlla se ogni nodo ha una label che viene condivisa dalla maggioranza dei suoi neighbors. Se così non è, si torna allo step 2.
\end{enumerate}
\end{frame}
\section{Performance}
\frame{\sectionpage}
\begin{frame}
\frametitle{Analisi delle performance della creazione del grafo (PP)}
Questa parte del programma, preliminare all'algoritmo di clustering, è stata inizialmente parallelizzata con Parallel Python.
\begin{itemize}
\item Due diversi sistemi HPC:
\begin{itemize}
\item elcid: 64 cores per nodo, AMD 6376 CPU, 2.3 GHz clock frequency
\item c3hpc: 24 cores per nodo, E5-2697 v2 Intel processor, 2.7 GHz clock frequency
\end{itemize}
\item Due diversi tipi di misure:
\begin{itemize}
\item Scalabilità fissando la dimensione del database e variando il numero di threads
\item Scalabilità fissando il numero di threads e variando la dimensione del database
\end{itemize}
\end{itemize}
\end{frame}
\begin{frame}
 \frametitle{Scalabilità della creazione della network per un dataset di 200K nodi (PP)}
 Scalabilità su un nodo del cluster c3hpc
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{label_200K.png}

\end{figure}
\end{frame}
\begin{frame}
 \frametitle{Scalabilità della creazione della network, 24 processori (PP)}
 \begin{center}
\begin{tabular}{|| c | c | c ||}
\hline
Size & Time \\ 
\hline
10000 & 7.61 \\
\hline
20000 & 21.28 \\
\hline
30000 & 42.36 \\
\hline
40000 & 78.06 \\
\hline
100000 & 404.81 \\
\hline
200000 & 1684.02 \\
\hline
300000 & 4035.33 \\
\hline
500000 & 10398.93 \\
\hline
700000 & 20509.69 \\
\hline
\end{tabular}
\end{center}
\end{frame}
\begin{frame}
 \frametitle{Scalabilità della creazione della network, 24 processori (PP)}
 Scalabilità su un intero nodo di c3hpc, size variabile da 10K a 700K
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{24coresb.png}

\end{figure}
\end{frame}

\begin{frame}
\frametitle{Problema}
Parallel Python procede copiando tutti gli oggetti necessari ai vari processi, dunque l'occupazione della memoria è proporzionale al numero di processi usati.\\
Di conseguenza il bottleneck è dato, oltre che dalla dimensione del dataset, dal numero di processi.
\begin{itemize}
\item Per elcid:
\begin{itemize}
\item 64 processi e 128 GB RAM per nodo $\rightarrow$ max size = $500K$
\end{itemize}
\item Per c3hpc:
\begin{itemize}
\item 24 processi e 64 GB RAM per nodo $\rightarrow$ max size = $700K$
\end{itemize}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Soluzione: una diversa libreria per la parallelizzazione}
Pur essendo, a parità di condizioni, leggermente meno efficiente di Parallel Python, la libreria multiprocessing risolve il problema della memoria essendo in grado di lavorare in memoria condivisa.
\begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{24cores_shared.png}

\end{figure}
\end{frame}
\begin{frame}
 \frametitle{Costo computazionale totale}
 \begin{itemize}
 \item $T_{TOT} = T_{COSTRUZIONE}+T_{ALGORITMO}+T_{OUTPUT}$
 \item $T_{OUTPUT} = T_{TAB1}+T_{TAB4}$
 \end{itemize}
 Le tabelle 1 e 4 sono gli output richiesti con i dati strettamente collegati alle communities.\\
 Il tempo di esecuzione dell'algoritmo di clustering è (in entrambi i casi) estremamente ridotto rispetto agli altri due tempi (dell'ordine di 2 minuti) e non viene parallelizzato.\\
 Anche la produzione degli output viene parallelizzata con multiprocessing.

\end{frame}
\begin{frame}
 \frametitle{Tabelle di output}
 \begin{itemize}
 \item Tabella 1 (nodi all'interno delle communities):
 \begin{itemize}
\item ID SOGGETTO
\item ID CF
\item ID COMMUNITY
\item DEGREE (connessioni all'interno della community)
\item NORM DEGREE (DEGREE/numero di nodi nella community)
\item CLOSENESS CENTRALITY
\item BETWEENNESS CENTRALITY
\item EIGENVECTOR CENTRALITY
\item PAGERANK
\end{itemize}
 \item Tabella 4 (communities):
 \begin{itemize}
 \item ID COMMUNITY
 \item NUMERO DI NODI
 \item NUMERO DI LINKS
 \item NUMERO DI LINKS MEDIO PER NODO
 \item LUNGHEZZA MASSIMA DI UNO SHORTEST PATH TRA DUE NODI
 \item CENTRALIZZAZIONE
 \end{itemize}
 \end{itemize}

\end{frame}
\begin{frame}
 \frametitle{Scalabilità per la creazione della tabella 1}
 Scalabilità su un intero nodo di c3hpc, size variabile da 10K a 1M
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{24cores_table1.png}

\end{figure}
\end{frame}

\begin{frame}
 \frametitle{Scalabilità per la creazione della tabella 4}
Scalabilità su un intero nodo di c3hpc, size variabile da 10K a 1M
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{24cores_table4.png}

\end{figure}
\end{frame}

\begin{frame}
 \frametitle{Scalabilità e confronto tra i vari tempi}

  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{24cores_total.png}

\end{figure}
\end{frame}
\begin{frame}
\frametitle{Osservazioni sulla scalabilità}
In generale, il tempo richiesto per la produzione delle tabelle non è trascurabile, rispetto al tempo richiesto dalla lettura e analisi dei dati, più l'implementazione dell'algoritmo, ed entrambi i tempi variano quadraticamente rispetto alla dimensione:
\begin{itemize}
\item L'algoritmo PageRank ha complessità O($|V|+|E|$), totale O($|V|^2+|V||E|$)
\item Il calcolo di tutte le Betweenness e Closeness Centralities va in O($|V|^2\log|V|+|V||E|$)
\item Il calcolo di tutti gli shortest paths va in O($|V|^2+|V||E|$)
\end{itemize}

\end{frame}
\begin{frame}
\frametitle{Analisi delle performance - riepilogo}
\begin{itemize}
\item Con Parallel Python non è possibile analizzare, per questioni di memoria, l'intero sottoinsieme di un milione di nodi costituito dai soggetti registrati negli ultimi 6 mesi
\item È possibile con multiprocessing a un costo minimo, avendo risolto il problema della memoria
\item Analizzando il consumo di memoria nei vari run, ci aspettiamo che la memoria non sarà un problema nemmeno al momento di analizzare l'intero dataset di soggetti (provvisti di codice fiscale), 7 milioni di nodi. Sarà necessario soltanto un numero maggiore di ore di calcolo.
\end{itemize}

\end{frame}
\section{Risultati}
\frame{\sectionpage}
\begin{frame}
 \frametitle{DBSCAN e Label propagation a confronto}
 I due algoritmi sono stati confrontati sul network provvisto dei soli link di tipo ``broker''. Due soggetti sono collegati nel network se:
 
 \begin{itemize}
\item Sono coinvolti in uno stesso preventivo (con due ruoli diversi)
\item Hanno richiesto almeno un preventivo tramite un agente (ID CODICE INTERMEDIARIO) comune. 
 \end{itemize}
 \end{frame}

\begin{frame}
 \frametitle{DBSCAN e Label propagation a confronto}
 I due algoritmi danno output sensibilmente diversi:
 \begin{center}
  \begin{tabular}{||c|c|c||}
\hline
 & DBSCAN & Label propagation \\ 
\hline
#communities & 197 & 42454 \\
\hline
#nodes in communities & 64210 & 155131 \\
\hline
max size & 56116 & 4284 \\
\hline
min size & 16 & 2 \\
\hline
\end{tabular}
\end{center}
In particolare, DBSCAN (con parametro $m = 15$) non individua le communities piccole del Label propagation, che sono molto probabilmente prive di \texit{core points}.\\
La community più grande ottenuta con DBSCAN verrebbe probabilmente splittata usando un $m$ maggiore.
\end{frame}
\begin{frame}
 \frametitle{Numero di nodi nelle communities - Label propagation}
 La differenza come numero di punti all'interno di cluster è quasi interamente compensata dalla presenza di communities piccole con Label propagation.
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{plot_net_nnodes.png}

\end{figure}
\end{frame}
\begin{frame}
\frametitle{DBSCAN e Label propagation a confronto}
Confronto sulle communities di size compresa tra 15 e 400
\begin{center}
  \begin{tabular}{||c|c|c||}
\hline
 & DBSCAN & Label propagation \\ 
\hline
#communities & 196 & 493 \\
\hline
#nodes in communities & 8044 & 37109 \\
\hline
max size & 350 & 396 \\
\hline
min size & 16 & 15 \\
\hline
\end{tabular}
\end{center}
\end{frame}
\begin{frame}
 \frametitle{Numero di nodi nelle communities - a confronto}
 Tagliando le communities sotto i 15 elementi di Label propagation, e quella più grande ottenuta con DBSCAN, i due andamenti sono molto più simili.
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{plot_nnodes.png}

\end{figure}
\end{frame}
\begin{frame}
 \frametitle{Norm degree - a confronto}
 Il norm degree è definito come il rapporto tra il degree (numero di connessioni) all'interno della community e il numero dei suoi nodi.
  \begin{figure}[htbp]
\centering
\includegraphics[height=6.0 cm,width=10 cm]{plot_ndegree.png}

\end{figure}
\end{frame}
\begin{frame}
\frametitle{Prossimi step}
Possibili modi di proseguire sull'analisi del link di tipo broker:
\begin{itemize}
\item Cercare di capire la relazione effettiva tra community e ruolo dei codici intermediario, ad esempio contando il numero totale di codici intermediario associati a un qualche nodo della community
\item Fare lo stesso con i codici segmento
\item Estrarre 100 codici intermediario, considerare i gruppi di nodi collegati a questi, e cercare di confrontarli con le communities ottenute dagli algoritmi
\item Fare lo stesso con 20 codici segmento.
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Step successivi}
\begin{itemize}
\item Eventuale tuning del parametro $m$ per DBSCAN, o tagli sulle size delle communities (entro 2 settimane)
\item Run con tutti i link sul database da 1M, con tuning dei parametri sui link probabilistici (entro fine mese)
\item Run con tutti i link sul database completo (entro metà novembre)
\item Consegna del lavoro (a seguire)
\end{itemize}
\end{frame}
\end{document}
